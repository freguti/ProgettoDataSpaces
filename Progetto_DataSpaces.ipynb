{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Progetto_DataSpaces.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqo8sy2kc5yTZsm/wFS6KR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/freguti/ProgettoDataSpaces/blob/main/Progetto_DataSpaces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjaEyBz9uvKw"
      },
      "source": [
        "#**Analysis of \"Predicting Pulsar Star\"**\n",
        "\n",
        "Simone Soncin - s263094\n",
        "\n",
        "DA FINIRE\n",
        "\n",
        "  Strumenti Utilizzati\n",
        "\n",
        "  Rivedere lettura grafici\n",
        "\n",
        "  VEDERE SE È IL CASO DI LASCIARE IL RATIO ORIGINALE.\n",
        "\n",
        "  Classificazione\n",
        "\n",
        "  Conclusioni\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGPeKiMJDTMs"
      },
      "source": [
        "##**Indice**\n",
        "\n",
        " \n",
        "\n",
        "1. [Introduzione](#Introduzione)\n",
        "2. [Analisi Dataset](#Analisi)\n",
        "3. [PCA](#PCA)\n",
        "4. [Bilanciamento Datadet](#bilanciamento)\n",
        "5. [Classificazione](#classificazione)\n",
        "  *   [Logistic Regression](#lr)\n",
        "  *   [Support Vector Machine](#svm)\n",
        "  *   [Naïve Bayes Classifier](#nbc)\n",
        "  *   [Random Forest Classifier](#rfc)\n",
        "  *   [K-Neares Neighbors Classifier](#knn)\n",
        "6. [Conclusioni](#conclusioni)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ryFeLG06Dcox",
        "outputId": "f1350ffc-3e65-4260-8170-2079b431ccd2"
      },
      "source": [
        "#Show/Hide code button\n",
        "from IPython.display import HTML\n",
        "HTML('''<script>\n",
        "code_show=true; \n",
        "function code_toggle() {\n",
        " if (code_show){\n",
        " $('div.input').hide();\n",
        " } else {\n",
        " $('div.input').show();\n",
        " }\n",
        " code_show = !code_show\n",
        "} \n",
        "$( document ).ready(code_toggle);\n",
        "</script>\n",
        "<form action=\"javascript:code_toggle()\">Il codice è stato nascosto per permettere una lettura più fluida. Per mostrarlo cliccare qui<br><input type=\"submit\" value=\"Abilita/Disabilita codice\"></form>''')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<script>\n",
              "code_show=true; \n",
              "function code_toggle() {\n",
              " if (code_show){\n",
              " $('div.input').hide();\n",
              " } else {\n",
              " $('div.input').show();\n",
              " }\n",
              " code_show = !code_show\n",
              "} \n",
              "$( document ).ready(code_toggle);\n",
              "</script>\n",
              "<form action=\"javascript:code_toggle()\">Il codice è stato nascosto per permettere una lettura più fluida. Per mostrarlo cliccare qui<br><input type=\"submit\" value=\"Abilita/Disabilita codice\"></form>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muG-UBR4Sp0g"
      },
      "source": [
        "<a name=\"introduzione\"></a>\n",
        "##**Introduzione**\n",
        "In questa tesina mi dedicherò ad analizzare un dataset, manipolare i dati per utilizzarli in maniera corretta e successivamente applicare dei modelli predittivi, identificando quale si comporta meglio nel nostro caso di studio.\n",
        "\n",
        "Le stelle pulsar sono delle stelle di neutroni che emettono un potente segnale radio dai poli misurabile dalla terra. Una stella pulsar ruota ad altissima velocità, rendendo questo segnale radio misurabile a tratti e fornendogli un pattern periodico che varia per ogni stella pulsar.\n",
        "\n",
        "Il dataset che utilizzerò è disponibile al link: https://www.kaggle.com/colearninglounge/predicting-pulsar-starintermediate?select=pulsar_data_train.csv \n",
        "\n",
        "Questo dataset contiene una serie di parametri continui discretizzati, i cui primi 4 sono derivati dal \"integrated pulse profile\", mentre gli ultimi 4 parametri sono ottenuti in maniera analoga dalla \"DM-SNR curve\".\n",
        "\n",
        "- Integrated profile: è ottenuto dal segnale periodico emesso dalla pulsar ed è univoco per ognuna di esse. Per questo motivo è utilizzato per identificarle a discapito del loro nome. \n",
        "- DM-SNR Curve: Dispersion Measure of the Signal to Noise Ratio in poche parole è la densità degli elettroni liberi lungo la linea ottica.\n",
        "\n",
        "I nostri parametri sono stati ottenuti da questi due dati, applicando rispettivamente la media, la deviazione standard, la curtosi (indica quanto sono spesse le code della distribuzione) e la simmetria statistica (asimmetria della distribuzione di probabilità rispetto alla sua media).\n",
        "\n",
        "Ecco la lista dettagliata dei parametri:\n",
        "- **Mean of the integrated profile**\n",
        "- **Standard deviation of the integrated profile**\n",
        "- **Excess kurtosis of the integrated profile**\n",
        "- **Skewness of the integrated profile**\n",
        "- **Mean of the DM-SNR curve**\n",
        "- **Standard deviation of the DM-SNR curve**\n",
        "- **Excess kurtosis of the DM-SNR curve**\n",
        "- **Skewness of the DM-SNR curve**\n",
        "\n",
        "Infine è presente un ultimo parametro discreto che indica se il segnale appartiene ad una pulsar (target_class = 1) o no (target_class = 0).\n",
        "\n",
        "###**Strumenti Utilizzati**\n",
        "\n",
        "- Grafici: Per i grafici è stata utilizzata la libreria chart studio, che permette di creare dei grafici interattivi in maniera semplice ed intuitiva. Questo strumento ha il limite che non consente un upload di dati superiore ai 500Kb. Per la creazione dei grafici a istogramma e a boxplot, ho dovuto dividere il grafico desiderato in 4 grafici più piccoli a causa del raggiungimento di tale limite. Ho provveduto ad abbinare le feature in base al calcolo statistico usato per l'estrazione dalla grandezza fisica misurata."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUhtNYajBu7q"
      },
      "source": [
        "##Utility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU9NzVhxkR6R"
      },
      "source": [
        "#Capture removes the cell's output\n",
        "%%capture\n",
        "#Imports\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "import numpy as np\n",
        "import functools\n",
        "import ipywidgets as widgets\n",
        "import sys\n",
        "from google.colab import drive\n",
        "!pip install -U imbalanced-learn\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install nbconvert\n",
        "!pip install -q gwpy\n",
        "import plotly\n",
        "!pip install chart_studio\n",
        "import chart_studio\n",
        "import chart_studio.plotly as py\n",
        "import plotly.graph_objs as go\n",
        "import plotly.figure_factory as ff\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split, KFold, GridSearchCV, learning_curve, cross_val_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from numpy import mean\n",
        "from scipy.cluster import hierarchy as hc\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#alla fine sarà da eseguire alla fine del notebook\n",
        "#%%capture\n",
        "#It's used to convert this notebook in HTML\n",
        "#!jupyter nbconvert --to html /content/drive/MyDrive/DataSpaces/Progetto_DataSpaces.ipynb"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hO-Q8hB5Vnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f5f9b9c-8269-40b1-8c58-11f5d24892d8"
      },
      "source": [
        "#Parameters\n",
        "%%capture\n",
        "chart_studio.tools.set_credentials_file(username='freguti', api_key='4T2iyEX3eZP4aJ8PEJye')\n",
        "HISTOGRAM_COLORS = {\"pulsar\" : \"#388004\",\n",
        "                    \"not_pulsar\" : \"#8B0000\"}\n",
        "drive.mount('/content/drive')\n",
        "BOX_OPACITY = 0.3\n",
        "COLOR_PALETTE = seaborn.color_palette(\"Blues_d\").as_hex()\n",
        "COLORSCALE_HEATMAP = [         [0.0, '#011f4b'],\n",
        "                [0.1111111111111111, '#03396c'], \n",
        "                [0.2222222222222222, '#005b96'], \n",
        "                [0.3333333333333333, '#2171b5'], \n",
        "                [0.4444444444444444, '#6497b1'], \n",
        "                [0.5555555555555556, '#6baed6'], \n",
        "                [0.6666666666666666, '#B0E2FF'], \n",
        "                [0.7777777777777778, '#b3cde0'], \n",
        "                [0.8888888888888888, '#bdd7e7'], \n",
        "                               [1.0, '#BFEFFF']] \n",
        "PALETTE_HEATMAP = [[0.0, '#F5FFFA'], \n",
        "                         [0.2, '#ADD8E6'], \n",
        "                         [0.4, '#87CEEB'],\n",
        "                         [0.6, '#87CEFA'], \n",
        "                         [0.8, '#40E0D0'], \n",
        "                         [1.0, '#00CED1']]\n",
        "\n",
        "LR_PARAM = [{\n",
        "    'clf__solver': ['liblinear'],\n",
        "    'clf__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "    'clf__penalty': ['l2', 'l1']\n",
        "},\n",
        "{\n",
        "    'clf__solver': ['newton-cg', 'lbfgs'], \n",
        "    'clf__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'clf__penalty': ['l2']\n",
        "}]\n",
        "SVM_PARAM = [\n",
        "{\n",
        "    'clf__kernel': ['linear'],\n",
        "    'clf__C': [0.1, 1, 10, 100],\n",
        "}, \n",
        "{\n",
        "    'clf__kernel': ['rbf'],\n",
        "    'clf__C': [0.1, 1, 10, 100],\n",
        "    'clf__gamma': [0.1, 1, 10, 100],\n",
        "}]\n",
        "\n",
        "RFC_PARAM = {\n",
        "    'clf__max_depth': [50, 75, 100],\n",
        "    'clf__max_features': [\"sqrt\", \"log2\"],\n",
        "    'clf__criterion': ['gini', 'entropy'],\n",
        "    'clf__n_estimators': [100, 300, 500]\n",
        "}\n",
        "\n",
        "KNN_PARAM = {\n",
        "    'clf__n_neighbors': [2, 3, 5, 10, 15],\n",
        "    'clf__weights': ['uniform', 'distance'],\n",
        "    'clf__p': [1, 2, 10]\n",
        "}\n",
        "\n",
        "NBC_PARAM = {}"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AX4XfWj3jX47d_k4vX9QZVO_OAZSjWe029I51p789XQ3FVSWYOiIqZv7i30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQSFps_4CVyD"
      },
      "source": [
        "%%capture\n",
        "#Graph utility\n",
        "\n",
        "def histogram_bar(tipo, data, col, visible=True, norm = \"\"):\n",
        "    \n",
        "    color = HISTOGRAM_COLORS[tipo]\n",
        "    \n",
        "    data_16 = data.astype(np.float16 ,copy=True)\n",
        "    \n",
        "    return go.Histogram(\n",
        "        x = data_16[col],\n",
        "        name = tipo,\n",
        "        marker = dict(color = color),\n",
        "        visible = visible,\n",
        "        opacity = 1,\n",
        "        histnorm=norm\n",
        "    )\n",
        "\n",
        "#fare l'istogramma con chart studio https://plotly.com/python/getting-started-with-chart-studio/\n",
        "def feature_histogram(dataset, title = \"\", feature = \"\"):\n",
        "\n",
        "  trace0 = histogram_bar(\"not_pulsar\", dataset[dataset['target_class'] == 0], feature)\n",
        "  trace1 = histogram_bar(\"pulsar\", dataset[dataset['target_class'] == 1], feature)\n",
        "  \n",
        "  data = [trace0, trace1]\n",
        "  \n",
        "  layout = dict(\n",
        "      title=title,\n",
        "      autosize=True,\n",
        "      yaxis=dict(\n",
        "          title='value',\n",
        "          automargin=True,\n",
        "      ),\n",
        "      legend=dict(\n",
        "          x=0,\n",
        "          y=1,\n",
        "      ),\n",
        "      barmode='group',\n",
        "      bargap=0.15,\n",
        "      bargroupgap=0.1\n",
        "  )\n",
        "  fig = dict(data=data, layout=layout)\n",
        "  return py.iplot(fig, filename=title)\n",
        "\n",
        "\n",
        "def on_slider_change(sender,dataset):\n",
        "  if sender['name'] == 'value':\n",
        "    selected_option = sender['owner'].value\n",
        "    print(selected_option)\n",
        "    feature_histogram(dataset = dataset, title = \"Distribuzione features\", feature = selected_option)\n",
        "\n",
        "def create_slider_controlled_histogram(col,pulsar,not_pulsar,first_plot):\n",
        "  pulsar_plot = []\n",
        "  not_pulsar_plot = []\n",
        "  hist_features,pulsar_plot,not_pulsar_plot = prepare_set(dataset.columns,first_plot,pulsar,not_pulsar)\n",
        "  active_index = 0\n",
        "\n",
        "  hist_not = [(histogram_bar('not_pulsar', not_pulsar_plot, col, False,'percent') if i != active_index\n",
        "            else histogram_bar('not_pulsar', not_pulsar_plot, col, True,'percent'))\n",
        "              for i, col in enumerate(hist_features)\n",
        "              ]\n",
        "  hist_pulsar = [(histogram_bar('pulsar', pulsar_plot, col, False,'percent') if i != active_index\n",
        "            else histogram_bar('pulsar', pulsar_plot, col, True,'percent'))\n",
        "              for i, col in enumerate(hist_features)\n",
        "              ]\n",
        "\n",
        "  total_data = hist_not + hist_pulsar\n",
        "  number_of_features = len(hist_features)\n",
        "  steps = []\n",
        "\n",
        "  for i in range(number_of_features):\n",
        "      step = dict(\n",
        "          method = 'restyle',\n",
        "          args = ['visible', [False] * number_of_features],\n",
        "          label = hist_features[i],\n",
        "      )\n",
        "      step['args'][1][i] = True\n",
        "      steps.append(step)\n",
        "      \n",
        "  sliders = [dict(\n",
        "      active = active_index,\n",
        "      currentvalue = dict(\n",
        "          prefix = \"Feature: \", \n",
        "          xanchor= 'center',\n",
        "      ),\n",
        "      pad = {\"t\": 50},\n",
        "      steps = steps,\n",
        "      len=1,\n",
        "  )]\n",
        "\n",
        "  layout = dict(\n",
        "      sliders=sliders,\n",
        "      autosize=True,\n",
        "      yaxis=dict(\n",
        "          title='valori',\n",
        "          automargin=True,\n",
        "      ),\n",
        "      legend=dict(\n",
        "          x=0,\n",
        "          y=1,\n",
        "      ),\n",
        "  )\n",
        "\n",
        "  fig = dict(data=total_data, layout=layout)\n",
        "\n",
        "  return py.iplot(fig, filename='bar_slider')  \n",
        "\n",
        "def create_box(type, data, col, visible=False):\n",
        "   \n",
        "    c = HISTOGRAM_COLORS[type]\n",
        "    data_16 = data.astype(np.float16 ,copy=True)\n",
        "    return go.Box(\n",
        "        y = data_16[col],\n",
        "        name = type,\n",
        "        marker = dict(color = c),\n",
        "        visible = visible,\n",
        "        opacity = BOX_OPACITY,\n",
        "    )\n",
        "\n",
        "def create_slider_controlled_Boxplot(col,pulsar,not_pulsar,first_plot):\n",
        "  pulsar_plot = []\n",
        "  not_pulsar_plot = []\n",
        "  box_features,pulsar_plot,not_pulsar_plot = prepare_set(dataset.columns,first_plot,pulsar,not_pulsar)\n",
        "  active_index = 0\n",
        "\n",
        "  box_not_pulsar = [(create_box('not_pulsar', not_pulsar_plot, col, False) if i != active_index\n",
        "            else create_box('not_pulsar', not_pulsar_plot, col, True))\n",
        "              for i, col in enumerate(box_features)\n",
        "              ]\n",
        "  box_pulsar = [(create_box('pulsar', pulsar_plot, col, False) if i != active_index\n",
        "              else create_box('pulsar', pulsar_plot, col, True))\n",
        "              for i, col in enumerate(box_features)\n",
        "              ]\n",
        "\n",
        "  data = box_not_pulsar + box_pulsar\n",
        "  number_of_features = len(box_features)\n",
        "  steps = []\n",
        "\n",
        "  for i in range(number_of_features):\n",
        "      step = dict(\n",
        "          method = 'restyle',  \n",
        "          args = ['visible', [False] * number_of_features],\n",
        "          label = box_features[i],\n",
        "      )\n",
        "      step['args'][1][i] = True # Toggle i'th trace to \"visible\"\n",
        "      steps.append(step)\n",
        "      \n",
        "  sliders = [dict(\n",
        "      active = active_index,\n",
        "      currentvalue = dict(\n",
        "          prefix = \"Feature: \", \n",
        "          xanchor= 'center',\n",
        "      ),\n",
        "      pad = {\"t\": 50},\n",
        "      steps = steps,\n",
        "      len=1,\n",
        "  )]\n",
        "\n",
        "  layout = dict(\n",
        "      sliders=sliders,\n",
        "      autosize=True,\n",
        "      yaxis=dict(\n",
        "          title='valori',\n",
        "          automargin=True,\n",
        "      ),\n",
        "      legend=dict(\n",
        "          x=0,\n",
        "          y=1,\n",
        "      ),\n",
        "  )\n",
        "\n",
        "  fig = dict(data=data, layout=layout)\n",
        "  return py.iplot(fig, filename='box_slider')\n",
        "\n",
        "def prepare_set(col,first_plot,pulsar,not_pulsar): \n",
        "  pulsar_plot = pulsar\n",
        "  not_pulsar_plot = not_pulsar\n",
        "  box_features = col.values.tolist()\n",
        "  if first_plot == \"mean\":\n",
        "    #to_drop = [box_features[1],box_features[2],box_features[3],box_features[5],box_features[6],box_features[7],box_features[8]]\n",
        "    #pulsar_plot = pulsar.drop(to_drop,axis =1)\n",
        "    #not_pulsar_plot = not_pulsar.drop(to_drop,axis =1)\n",
        "    hist_features = [box_features[0],box_features[4]]\n",
        "  if first_plot == \"deviation\":\n",
        "    #to_drop = [box_features[0],box_features[2],box_features[3],box_features[4],box_features[6],box_features[7],box_features[8]]\n",
        "    #pulsar_plot = pulsar.drop(to_drop,axis =1)\n",
        "    #not_pulsar_plot = not_pulsar.drop(to_drop,axis =1)\n",
        "    hist_features = [box_features[1],box_features[5]]\n",
        "  if first_plot == \"kurtosis\":\n",
        "    #to_drop = [box_features[0],box_features[1],box_features[3],box_features[4],box_features[5],box_features[7],box_features[8]]\n",
        "    #pulsar_plot = pulsar.drop(to_drop,axis =1)\n",
        "    #not_pulsar_plot = not_pulsar.drop(to_drop,axis =1)\n",
        "    hist_features = [box_features[2],box_features[6]]\n",
        "  if first_plot == \"skewness\":\n",
        "    #to_drop = [box_features[0],box_features[1],box_features[2],box_features[4],box_features[5],box_features[6],box_features[8]]\n",
        "    #pulsar_plot = pulsar.drop(to_drop,axis =1)\n",
        "    #not_pulsar_plot = not_pulsar.drop(to_drop,axis =1)\n",
        "    hist_features = [box_features[3],box_features[7]]\n",
        "  return hist_features,pulsar_plot,not_pulsar_plot\n",
        "\n",
        "def plot_variance(pca, title):\n",
        "  tot_var = np.sum(pca.explained_variance_)\n",
        "  ex_var = [(i / tot_var) * 100 for i in sorted(pca.explained_variance_, reverse=True)]\n",
        "  cum_ex_var = np.cumsum(ex_var)\n",
        "\n",
        "  cum_var_bar = go.Bar(\n",
        "      x=list(range(1, len(cum_ex_var) + 1)), \n",
        "      y=ex_var,\n",
        "      name=\"Varianza di ogni componente\",\n",
        "      marker=dict(\n",
        "          color=HISTOGRAM_COLORS[\"pulsar\"],\n",
        "      ),\n",
        "      opacity= 1\n",
        "      )\n",
        "\n",
        "  variance_line = go.Scatter(\n",
        "      x=list(range(1, len(cum_ex_var) + 1)),\n",
        "      y=cum_ex_var,\n",
        "      mode='lines+markers',\n",
        "      name=\"Varianza cumulativa\",\n",
        "      marker=dict(\n",
        "          color=HISTOGRAM_COLORS[\"not_pulsar\"],\n",
        "      ),\n",
        "      opacity= 1,\n",
        "      line=dict(\n",
        "          shape='hv',\n",
        "      ))\n",
        "  data = [cum_var_bar, variance_line]\n",
        "  layout = go.Layout(\n",
        "      autosize=True,\n",
        "      title=title,\n",
        "      yaxis=dict(\n",
        "          title='Varianza (%)',\n",
        "      ),\n",
        "      xaxis=dict(\n",
        "          title=\"Componenti principali\",\n",
        "          dtick=1,\n",
        "          rangemode='nonnegative'\n",
        "      ),\n",
        "      legend=dict(\n",
        "          x=0,\n",
        "          y=1,\n",
        "      ),\n",
        "  )\n",
        "  fig = go.Figure(data=data, layout=layout)\n",
        "  return py.iplot(fig, filename=title)\n",
        "\n",
        "def PCA_Reduction(X_norm, plot = False , n_components = 8):\n",
        "  pca = PCA(random_state=42) #random seed\n",
        "  ortogonal = pca.fit_transform(X_norm)\n",
        "\n",
        "  if plot:\n",
        "      p = plot_variance(pca, \"Varianza singola e cumulativa\")\n",
        "\n",
        "  pca.components_ = pca.components_[:n_components]\n",
        "  reduced_data = np.dot(ortogonal, pca.components_.T)\n",
        "  X_red = pd.DataFrame(reduced_data, columns=[\"PC#%d\" % (x + 1) for x in range(n_components)])\n",
        "  if plot:\n",
        "      return p, X_red\n",
        "  else:\n",
        "      return X_red\n",
        "\n",
        "def grid_search_cv(model, params, X_train, y_train, cv):\n",
        "  over = SMOTE(sampling_strategy=0.4)\n",
        "  under = RandomUnderSampler(sampling_strategy=0.6)\n",
        "  steps = [('over', over), ('under', under), ('model', model)]\n",
        "  pipeline = Pipeline(steps=steps)\n",
        "  grid_search = GridSearchCV(estimator=pipeline, \n",
        "                              param_grid=params, \n",
        "                              cv=cv, \n",
        "                              n_jobs=-1,       # Use all processors\n",
        "                              scoring='f1',    # Use f1 metric for evaluation\n",
        "                              return_train_score=True)\n",
        "  grid_search.fit(X_train, y_train)\n",
        "  return grid_search"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jONDdFWm3tZZ"
      },
      "source": [
        "<a name=\"Analisi\"></a>\n",
        "##**Analisi Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfng4uxpmYN3"
      },
      "source": [
        "Come prima cosa è necessario eseguire un'analisi del dataset, eseguendo eventualmente delle operazioni per migliorarlo e renderlo più adatto al nostro tipo di analisi.\n",
        "\n",
        "La fase di analisi è la più importante, perchè permette di pulire il dataset migliorando l'analisi effettuata e ridurre la potenza di calcolo necessaria per eseguirla.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1leO2hjh7Ge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e359d70b-1556-4ff4-a48c-e2b8acf7bebd"
      },
      "source": [
        "dataset = pd.read_csv('/content/drive/My Drive/DataSpaces/pulsar_stars.csv')\n",
        "for column in dataset:\n",
        " if dataset[column].dtype == 'float64':\n",
        "  dataset[column]=pd.to_numeric(dataset[column], downcast='float')\n",
        "  if dataset[column].min() <= np.finfo(np.float16).min or dataset[column].max() >= np.finfo(np.float16).max:\n",
        "    raise CustomError(\"Range Exception\")\n",
        " if dataset[column].dtype == 'int64':\n",
        "  dataset[column]=pd.to_numeric(dataset[column], downcast='integer')\n",
        "\n",
        "print(\"il dataset ha %d record e %d features\\n\\nNumero di valori null per ogni feature:\" % dataset.shape)\n",
        "print(dataset.isnull().sum())\n",
        "\n",
        "print(\"\\nDa quel che si può vedere, non ci sono valori nulli all'interno del nostro dataset. Nel caso in cui ne avessimo trovato uno avremo avuto due possibilità:\\n\")\n",
        "print(\"- Se i valori nulli non sono molti possiamo procedere eliminando i record che riportano il valore nullo;\\n- Se il numero di questi valori nulli è elevato si può procedere alla sostituzione con dei valori di default\\n\")\n",
        "\n",
        "print(\"ci sono 2 classi differenti.\\n0 -> non è una pulsar\\n1 -> è una pulsar\")\n",
        "X, y = make_classification(n_classes = 2, )\n",
        "target_class = dataset['target_class'].value_counts()\n",
        "print(\"numero di record per ogni classe:\\n\" + target_class.to_string() + \"\\n\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "il dataset ha 17898 record e 9 features\n",
            "\n",
            "Numero di valori null per ogni feature:\n",
            " Mean of the integrated profile                  0\n",
            " Standard deviation of the integrated profile    0\n",
            " Excess kurtosis of the integrated profile       0\n",
            " Skewness of the integrated profile              0\n",
            " Mean of the DM-SNR curve                        0\n",
            " Standard deviation of the DM-SNR curve          0\n",
            " Excess kurtosis of the DM-SNR curve             0\n",
            " Skewness of the DM-SNR curve                    0\n",
            "target_class                                     0\n",
            "dtype: int64\n",
            "\n",
            "Da quel che si può vedere, non ci sono valori nulli all'interno del nostro dataset. Nel caso in cui ne avessimo trovato uno avremo avuto due possibilità:\n",
            "\n",
            "- Se i valori nulli non sono molti possiamo procedere eliminando i record che riportano il valore nullo;\n",
            "- Se il numero di questi valori nulli è elevato si può procedere alla sostituzione con dei valori di default\n",
            "\n",
            "ci sono 2 classi differenti.\n",
            "0 -> non è una pulsar\n",
            "1 -> è una pulsar\n",
            "numero di record per ogni classe:\n",
            "0    16259\n",
            "1     1639\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ah__nVazvgK"
      },
      "source": [
        "La prima analisi che si dovrà effettuare è quella che permette di verificare i tipi di dati del dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "YmLz7Zwqt6X-",
        "outputId": "a8a0be94-611b-4317-b3b1-77a4a5f5a49e"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mean of the integrated profile</th>\n",
              "      <th>Standard deviation of the integrated profile</th>\n",
              "      <th>Excess kurtosis of the integrated profile</th>\n",
              "      <th>Skewness of the integrated profile</th>\n",
              "      <th>Mean of the DM-SNR curve</th>\n",
              "      <th>Standard deviation of the DM-SNR curve</th>\n",
              "      <th>Excess kurtosis of the DM-SNR curve</th>\n",
              "      <th>Skewness of the DM-SNR curve</th>\n",
              "      <th>target_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>140.562500</td>\n",
              "      <td>55.683781</td>\n",
              "      <td>-0.234571</td>\n",
              "      <td>-0.699648</td>\n",
              "      <td>3.199833</td>\n",
              "      <td>19.110426</td>\n",
              "      <td>7.975532</td>\n",
              "      <td>74.242226</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>102.507812</td>\n",
              "      <td>58.882431</td>\n",
              "      <td>0.465318</td>\n",
              "      <td>-0.515088</td>\n",
              "      <td>1.677258</td>\n",
              "      <td>14.860146</td>\n",
              "      <td>10.576487</td>\n",
              "      <td>127.393578</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>103.015625</td>\n",
              "      <td>39.341648</td>\n",
              "      <td>0.323328</td>\n",
              "      <td>1.051164</td>\n",
              "      <td>3.121238</td>\n",
              "      <td>21.744669</td>\n",
              "      <td>7.735822</td>\n",
              "      <td>63.171909</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>136.750000</td>\n",
              "      <td>57.178448</td>\n",
              "      <td>-0.068415</td>\n",
              "      <td>-0.636238</td>\n",
              "      <td>3.642977</td>\n",
              "      <td>20.959280</td>\n",
              "      <td>6.896499</td>\n",
              "      <td>53.593662</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>88.726562</td>\n",
              "      <td>40.672226</td>\n",
              "      <td>0.600866</td>\n",
              "      <td>1.123492</td>\n",
              "      <td>1.178930</td>\n",
              "      <td>11.468719</td>\n",
              "      <td>14.269573</td>\n",
              "      <td>252.567307</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Mean of the integrated profile  ...  target_class\n",
              "0                       140.562500  ...             0\n",
              "1                       102.507812  ...             0\n",
              "2                       103.015625  ...             0\n",
              "3                       136.750000  ...             0\n",
              "4                        88.726562  ...             0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttDLgb2U0vmh"
      },
      "source": [
        "Possiamo notare che tutte le features tranne la classe sono reali, perchè sono il prodotto di calcoli statistici su dei fenomeni fisici e quindi intrinsecamente continui.\n",
        "La classe di appartenenza invece è discreta, e visto che può assumere due valori possiamo dichiarare che il nostro problema consiste in una classificazione di tipo binario.\n",
        "\n",
        "Un'altra analisi preliminare che possiamo eseguire consiste nell'analizzare dei dati statistici relativi ai nostri campi del dataset. Questa analisi estrapolerà questi valori:\n",
        "\n",
        "- **count:** specifica il numero dei record presenti nel dataset\n",
        "- **mean:** specifica la media dell'attributo calcolata per tutti i record\n",
        "- **std:** specifica la deviazione standard dell'attributo\n",
        "- **min:** specifica il valore minimo dell'attributo\n",
        "- **25%:** il 25% dei record ha un valore minore di quello visualizzato (lower percentile)\n",
        "- **50%:** il 50% dei record ha un valore minore di quello visualizzato (median percentile)\n",
        "- **75%:** il 75% dei record ha un valore minore di quello visualizzato (upper percentile)\n",
        "- **max:** specifica il valore massimo dell'attributo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "zbrmcfcR2oSQ",
        "outputId": "57842cb0-d6b8-453b-a5e3-f98df8122b67"
      },
      "source": [
        "dataset.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mean of the integrated profile</th>\n",
              "      <th>Standard deviation of the integrated profile</th>\n",
              "      <th>Excess kurtosis of the integrated profile</th>\n",
              "      <th>Skewness of the integrated profile</th>\n",
              "      <th>Mean of the DM-SNR curve</th>\n",
              "      <th>Standard deviation of the DM-SNR curve</th>\n",
              "      <th>Excess kurtosis of the DM-SNR curve</th>\n",
              "      <th>Skewness of the DM-SNR curve</th>\n",
              "      <th>target_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>17898.000000</td>\n",
              "      <td>17898.000000</td>\n",
              "      <td>17898.000000</td>\n",
              "      <td>17898.000000</td>\n",
              "      <td>17898.000000</td>\n",
              "      <td>17898.000000</td>\n",
              "      <td>17898.000000</td>\n",
              "      <td>17898.000000</td>\n",
              "      <td>17898.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>111.079773</td>\n",
              "      <td>46.549370</td>\n",
              "      <td>0.477856</td>\n",
              "      <td>1.770286</td>\n",
              "      <td>12.614424</td>\n",
              "      <td>26.326546</td>\n",
              "      <td>8.303542</td>\n",
              "      <td>104.857712</td>\n",
              "      <td>0.091574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>25.652920</td>\n",
              "      <td>6.843179</td>\n",
              "      <td>1.064041</td>\n",
              "      <td>6.167913</td>\n",
              "      <td>29.472887</td>\n",
              "      <td>19.470539</td>\n",
              "      <td>4.506091</td>\n",
              "      <td>106.514359</td>\n",
              "      <td>0.288432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.812500</td>\n",
              "      <td>24.772041</td>\n",
              "      <td>-1.876011</td>\n",
              "      <td>-1.791886</td>\n",
              "      <td>0.213211</td>\n",
              "      <td>7.370432</td>\n",
              "      <td>-3.139270</td>\n",
              "      <td>-1.976976</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>100.929688</td>\n",
              "      <td>42.376019</td>\n",
              "      <td>0.027098</td>\n",
              "      <td>-0.188572</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>14.437331</td>\n",
              "      <td>5.781506</td>\n",
              "      <td>34.960505</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>115.078125</td>\n",
              "      <td>46.947479</td>\n",
              "      <td>0.223240</td>\n",
              "      <td>0.198710</td>\n",
              "      <td>2.801839</td>\n",
              "      <td>18.461315</td>\n",
              "      <td>8.433515</td>\n",
              "      <td>83.064556</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>127.085938</td>\n",
              "      <td>51.023203</td>\n",
              "      <td>0.473325</td>\n",
              "      <td>0.927783</td>\n",
              "      <td>5.464256</td>\n",
              "      <td>28.428104</td>\n",
              "      <td>10.702959</td>\n",
              "      <td>139.309326</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>192.617188</td>\n",
              "      <td>98.778908</td>\n",
              "      <td>8.069522</td>\n",
              "      <td>68.101624</td>\n",
              "      <td>223.392136</td>\n",
              "      <td>110.642212</td>\n",
              "      <td>34.539845</td>\n",
              "      <td>1191.000854</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Mean of the integrated profile  ...  target_class\n",
              "count                     17898.000000  ...  17898.000000\n",
              "mean                        111.079773  ...      0.091574\n",
              "std                          25.652920  ...      0.288432\n",
              "min                           5.812500  ...      0.000000\n",
              "25%                         100.929688  ...      0.000000\n",
              "50%                         115.078125  ...      0.000000\n",
              "75%                         127.085938  ...      0.000000\n",
              "max                         192.617188  ...      1.000000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX0SCNL86PXg"
      },
      "source": [
        "###Grafici"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5fam4xx-XnL"
      },
      "source": [
        "####Istogramma"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "89BQ9U4VtsmL",
        "outputId": "3fd64890-449b-4b4a-8091-e11f2313d129"
      },
      "source": [
        "feature_histogram(dataset = dataset, title = \"Distribuzione delle classi\", feature = \"target_class\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"525px\"\n",
              "            src=\"https://plotly.com/~freguti/15.embed\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f9a82b48dd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEwUWW8m3FS-"
      },
      "source": [
        "Da quel che possiamo vedere il dataset che abbiamo è molto sbilanciato. Per ogni record di classe \"1\" esistono 10 record di classe \"0\".\n",
        "\n",
        "Questo sbilanciamento potrebbe portare il modello predittivo ad avere dei bias, portandolo a predirre più frequentemente la classe con più campioni solamente perchè è stata più presente in fase di train.\n",
        "\n",
        "Gli Istogrammi sono molto utili per vedere la distribuzione delle classi per ogni feature in relazione al suo valore.\n",
        "Tramite uno slider è possibile visualizzare delle features diverse."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "jJhTutRh0s4L",
        "outputId": "ad236f04-12d4-4a55-cb81-ba45680a9bc0"
      },
      "source": [
        "pulsar = dataset[dataset['target_class'] == 1]\n",
        "not_pulsar = dataset[dataset['target_class'] == 0]\n",
        "\n",
        "create_slider_controlled_histogram(dataset.columns,pulsar,not_pulsar, \"mean\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' Mean of the integrated profile', ' Mean of the DM-SNR curve']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"525px\"\n",
              "            src=\"https://plotly.com/~freguti/26.embed\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f9a829caed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eqc_yIJGdxD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "outputId": "9365e299-197a-4052-c6fa-093999c41a1d"
      },
      "source": [
        "create_slider_controlled_histogram(dataset.columns,pulsar,not_pulsar,\"deviation\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' Standard deviation of the integrated profile', ' Standard deviation of the DM-SNR curve']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"525px\"\n",
              "            src=\"https://plotly.com/~freguti/26.embed\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f9a8434aed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "jJ3qWR0nGVRX",
        "outputId": "03bac4fa-d557-46a4-ff87-117f07186453"
      },
      "source": [
        "create_slider_controlled_histogram(dataset.columns,pulsar,not_pulsar,\"kurtosis\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' Excess kurtosis of the integrated profile', ' Excess kurtosis of the DM-SNR curve']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"525px\"\n",
              "            src=\"https://plotly.com/~freguti/26.embed\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f9a83436fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "2EJ7rATXcW5T",
        "outputId": "a0b159a1-2c2f-4f84-8f98-e5d83f96c53f"
      },
      "source": [
        "create_slider_controlled_histogram(dataset.columns,pulsar,not_pulsar,\"skewness\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' Skewness of the integrated profile', ' Skewness of the DM-SNR curve']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"525px\"\n",
              "            src=\"https://plotly.com/~freguti/26.embed\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f9a84297410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56fdYyeMy1Hy"
      },
      "source": [
        "A causa di un limite dello strumento, che consente un upload limitato di dati, ho dovuto dividere il grafico in 4. Ho optato per separare i grafici per metodo statistico applicato alle due misurazioni.\n",
        "\n",
        "ho usato una normalizzazione percentuale che mi mostra, per ogni classe, la distribuzione percentuale dei valori. L'ho fatto a causa dell'elevata differenza numerica tra le due classi, che non mi permetteva di mostrare correttamente i valori assoluti.\n",
        "\n",
        "Si può notare che la distribuzione dei valori \"non pulsar\" tende ad essere la maggior parte delle volte una distribuzione Gaussiana, e ogni tanto una distribuzione di Poisson.\n",
        "\n",
        "La distribuzione dei valori \"pulsar\" tende ad essere più costante e disordinata, evitando una concentrazione di valori. Questo deriva dalle nostre supposizioni iniziali, che indicavano come univoci i pattern di ogni pulsar.\n",
        "\n",
        "Questa differenza può essere significativa in fase di classificazione, perchè le varie features tendono a sovrapporsi poche volte, ciò implica che potenzialmente tutte le classi possono essere utili per determinare la classe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8Pl9OFp9-K5"
      },
      "source": [
        "####Boxplot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "XcTcYxCTNAMR",
        "outputId": "5dfec82b-7135-46e8-aabd-a0dc10da41f3"
      },
      "source": [
        "create_slider_controlled_Boxplot(dataset.columns,pulsar,not_pulsar, \"mean\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"525px\"\n",
              "            src=\"https://plotly.com/~freguti/65.embed\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f9a82597350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "gGo-h1rfQx2Q",
        "outputId": "0c2c80b9-8152-4a12-f06e-1f28c6dbdad6"
      },
      "source": [
        "create_slider_controlled_Boxplot(dataset.columns,pulsar,not_pulsar, \"deviation\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"525px\"\n",
              "            src=\"https://plotly.com/~freguti/65.embed\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f9a831f5290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "kMmOM1dIQyOM",
        "outputId": "41101069-556b-496b-8159-a1263674e1c3"
      },
      "source": [
        "create_slider_controlled_Boxplot(dataset.columns,pulsar,not_pulsar, \"kurtosis\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"525px\"\n",
              "            src=\"https://plotly.com/~freguti/65.embed\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f9a832c8910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "sMQTI5QonXW0",
        "outputId": "2279a051-9b2e-431f-90d6-6f3358b1467a"
      },
      "source": [
        "create_slider_controlled_Boxplot(dataset.columns,pulsar,not_pulsar, \"skewness\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"525px\"\n",
              "            src=\"https://plotly.com/~freguti/65.embed\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f9a82982310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8wxYPlhRJxI"
      },
      "source": [
        "Sembra che tutti i parametri siano rilevanti nella classificazione. Nessuno di loro ha una distribuzione media troppo simile alla controparte della classe opposta. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKkE3YA--UeL"
      },
      "source": [
        "####Matrice di correlazione"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXUhKSZWsJ2v"
      },
      "source": [
        "Una matrice di correlazione è una tabella che mostra i coefficienti di correlazione tra insiemi di variabili. Ogni variabile casuale ( $X_i$ ) nella tabella è correlata con ciascuno degli altri valori nella tabella ( $X_j$ ); questo permette di vedere quali coppie hanno la più alta correlazione. La correlazione si riferisce a qualsiasi associazione statistica, ma nell'uso comune del termine si indica quanto due variabili siano vicine ad avere una relazione lineare l'una con l'altra.\n",
        "\n",
        "Nel grafico sottostante abbiamo utilizzato la correlazione di Pearson, che misura la correlazione lineare tra due variabili statistiche X e Y, ritornando un valore compreso tra -1 e 1.\n",
        "- Se il valore è vicino a -1 vuol dire che le due variabili hanno una forte correlazione negativa, cioè al crescere della prima decresce la seconda;\n",
        "- Se il valore è vicino a 1 vuol dire che le due variabili hanno una forte correlazione, cioè al crescere della prima crescerà anche la seconda;\n",
        "- Se il valore è vicino allo 0 le due variabili sono scorrelate\n",
        "\n",
        "Questo valore viene calcolato così: $Corr_{i,j} = \\frac{cov(X,Y)}{\\sigma_x\\sigma_y}$\n",
        "\n",
        "dove cov è la covarianza tra i due valori e $\\sigma$ è lo scarto quadratico medio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871
        },
        "id": "t0gFY-ChbLHf",
        "outputId": "69a9b885-6460-475e-dd88-138d9df9e94f"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "corr = dataset.corr(method='pearson')\n",
        "#corr.style.background_gradient(cmap='coolwarm').set_precision(2)\n",
        "title = \"Correlation Matrix\"\n",
        "\n",
        "z_text = np.around(corr.values.tolist(), decimals=2)\n",
        "\n",
        "figure = ff.create_annotated_heatmap(z=corr.values, \n",
        "                                         x=corr.columns.tolist(), \n",
        "                                         y=corr.index.tolist(),\n",
        "                                         annotation_text=z_text,\n",
        "                                         colorscale=PALETTE_HEATMAP,\n",
        "                                         showscale=True)\n",
        "\n",
        "figure.layout.title = title\n",
        "figure.layout.autosize = False\n",
        "figure.layout.width = 850\n",
        "figure.layout.height = 850\n",
        "figure.layout.margin = go.layout.Margin(l=140, r=100, b=200, t=80)\n",
        "figure.layout.xaxis.update(side='bottom')\n",
        "figure.layout.yaxis.update(side='left')\n",
        "\n",
        "for i in range(len(figure.layout.annotations)):\n",
        "    figure.layout.annotations[i].font.size = 8\n",
        "                                \n",
        "py.iplot(figure, filename=title)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"850px\"\n",
              "            height=\"850px\"\n",
              "            src=\"https://plotly.com/~freguti/106.embed\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7fd13614b550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMGCos5csnL6"
      },
      "source": [
        "Possiamo notare che sia la skewness e la kurtosis (0,95 per l'integrated profile e 0,92 per la DM-SNR curve) che la mean e la standard deviation (0,55 per l'integrated profile e 0,80 per la DM-SNR curve) sono estremamente correlate tra loro.\n",
        "\n",
        "Essendo che i nostri parametri sono ricavati dall'applicazione di funzioni statistiche su due grandezze fisiche, era aspettato trovare due blocchi di forte correlazione all'interno della matrice.\n",
        "\n",
        "Possiamo notare come la kurtosis e la skewness of the integrated profile siano estremamente importanti per determinare la target_class, mentre la mean e la standard deviation della DM-SNR curve sono meno importanti, ma comunque molto rilevanti. Anche la mean of integrated profile ha una correlazione significativa (-0,68), cioè ha una forte correlazione inversa.\n",
        "\n",
        "Notiamo che nessun attributo ha un indice di correlazione con la target_class vicino allo 0, ciò significa che sono tutti importanti nella determinazione della classe. Possiamo notare che comunque possiamo eliminare i 3 attributi che hanno un indice di correlazione molto alto ($|M_{i,j}|>= 0,80$) tra loro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTjBRUgS-l4h"
      },
      "source": [
        "####Dendrogramma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHPVEOyBC5mY"
      },
      "source": [
        "Un dendrogramma è un grafo ad albero utilizzato per raffigurare la disposizione dei cluster relativi alle features. L'obiettivo è quello di visualizzare somiglianze tra i cluster, rilevando potenziali caratteristiche duplicate e potenzialmente aiutando nella riduzione della dimensionalità.\n",
        "\n",
        "Questo grafico indica la forza delle relazioni esistenti tra due cluster in base alla distanza che intercorre tra l'origine e la linea verticale più vicina che connette le linee orizzontali corrispondenti ai due elementi considerati."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "uDOQAvNIDazv",
        "outputId": "deca678c-3dc3-4552-8b83-5a58f7ee9eb7"
      },
      "source": [
        "names = dataset.columns\n",
        "inv_corr = 1 - corr # This is the 'dissimilarity' method\n",
        "\n",
        "fig = ff.create_dendrogram(inv_corr, \n",
        "                           labels=names, \n",
        "                           colorscale=COLOR_PALETTE,\n",
        "                           linkagefun=lambda x: hc.linkage(x, 'average'))\n",
        "\n",
        "fig['layout'].update(dict(\n",
        "    title=\"Dendrogramma di correlazione tra gli attributi\",\n",
        "    width=800, \n",
        "    height=600,\n",
        "    xaxis=dict(\n",
        "        title='Features',\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        title='Distance',\n",
        "    ),\n",
        "))\n",
        "py.iplot(fig, filename='dendrogram_corr_clustering')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800px\"\n",
              "            height=\"600px\"\n",
              "            src=\"https://plotly.com/~freguti/104.embed\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7fd1351cabd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-I50cHLHh4n"
      },
      "source": [
        "DA RIVEDERE\n",
        "\n",
        "Non avendo distanze piccole tra i vari cluster, possiamo rafforzare la nostra idea di mantenere tutti gli attributi durante la fase di classificazione."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_dUfjXNJ9Oj"
      },
      "source": [
        "###Suddivisione del dataset e normalizzazione dei dati\n",
        "\n",
        "Per evitare \"data leakage\" è importante eseguire ogni trasformazione dopo la separazione dei dati. Il test set deve simulare dei dati reali acquisiti dopo l'addestramento del nostro modello, quindi non può essere utilizzato in nessun caso insieme al train set.\n",
        "\n",
        "Molte volte i dataset contengono dei dati che variano molto rispetto alla media in termini di grandezza. Molti algoritmi di classificazione utilizzano la distanza euclidea per misurare la distanza tra due dati, quindi delle distanze troppo grandi possono causare dei problemi.\n",
        "\n",
        "Per questo motivo, due features diverse possono influenzare in maniera diversa il classificatore in base all'unità di misura. Per esempio una features i cui valori sono dell'ordine delle migliaia (900, 5000, 2000) avrà un peso maggiore di una feature con valori nell'ordine delle unità (0,1, 10, 100) anche se in percentuale la variazione della prima risulterebbe essere minore rispetto alla seconda.\n",
        "\n",
        "Per ovviare a questo problema utilizzeremo lo StandardScaler, che normalizzerà i nostri dati sottraendogli la media e dividendoli per lo scarto quadratico medio:\n",
        "$x' = \\frac{x - \\mu_x}{\\sigma_x}$\n",
        "\n",
        "La normalizzazione verrà eseguita dopo la suddivisione dei dati, perchè il test set non deve essere influenzato in alcun modo dal train set e, eseguendo la normalizzazione sull'intero dataset, lo influenzerei tramite la media e la varianza del dataset intero.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYgY4lbSKJHL"
      },
      "source": [
        "def normalize(X_set):\n",
        "  scaler = StandardScaler(with_mean=True, with_std=True, copy=True)\n",
        "  return scaler.fit_transform(X_set)\n",
        "\n",
        "X_dataset = dataset.drop(['target_class'], axis=1)\n",
        "y_data = dataset['target_class']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_dataset,y_data, test_size=0.2, random_state=42, stratify=y_data)\n",
        "X_train_norm = normalize(X_train)\n",
        "X_test_norm = normalize(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ks_p_6K73NOl"
      },
      "source": [
        "<a name=\"PCA\"></a>\n",
        "##Principal Component Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kJXZvriSX7f"
      },
      "source": [
        "La Principal Component Analysis (PCA) è una tecnica che consente di ridurre la dimensionalità del dataset, proiettando negli assi principali gli attributi con maggior varianza.\n",
        "La variazione di complessità avviene limitandosi ad analizzare le variabili con maggior varianza, quindi, più importanti.\n",
        "\n",
        "Essendo che le componenti vengono inserite man mano in nuovi assi, si otterrà una base ortogonale nella quale tutte le componenti aggiunte saranno a loro volta ortogonali alle precedenti.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "9weE_fxAK-Rv",
        "outputId": "219a9d61-1448-4143-e17d-a1d978c0e48c"
      },
      "source": [
        "p, x_train_PCA6 = PCA_Reduction(X_train_norm, plot = True , n_components = 6)\n",
        "x_train_PCA4 = PCA_Reduction(X_train_norm, plot = False , n_components = 4)\n",
        "p"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"525px\"\n",
              "            src=\"https://plotly.com/~freguti/122.embed\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7fd135cc2fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "C25h0FiHaC4W",
        "outputId": "950f3aed-1111-4d50-a0ab-9f7a68c28456"
      },
      "source": [
        "x_train_PCA6.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PC#1</th>\n",
              "      <th>PC#2</th>\n",
              "      <th>PC#3</th>\n",
              "      <th>PC#4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-2.463495</td>\n",
              "      <td>-2.561296</td>\n",
              "      <td>0.358478</td>\n",
              "      <td>-0.816815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.221554</td>\n",
              "      <td>-0.398319</td>\n",
              "      <td>0.064316</td>\n",
              "      <td>0.146490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.568718</td>\n",
              "      <td>0.347144</td>\n",
              "      <td>0.085768</td>\n",
              "      <td>-0.013019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.767799</td>\n",
              "      <td>-0.632460</td>\n",
              "      <td>-0.086334</td>\n",
              "      <td>0.430180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-2.056926</td>\n",
              "      <td>-1.624101</td>\n",
              "      <td>-0.212691</td>\n",
              "      <td>-0.535097</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       PC#1      PC#2      PC#3      PC#4\n",
              "0 -2.463495 -2.561296  0.358478 -0.816815\n",
              "1 -0.221554 -0.398319  0.064316  0.146490\n",
              "2  0.568718  0.347144  0.085768 -0.013019\n",
              "3 -0.767799 -0.632460 -0.086334  0.430180\n",
              "4 -2.056926 -1.624101 -0.212691 -0.535097"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T6cSd_GQqyk"
      },
      "source": [
        "Quello che possiamo leggere da questo grafico è che già con le prime 4 componenti principali raggiungiamo una varianza cumulativa del 94,35%.\n",
        "\n",
        "Possiamo ridurre la complessità del nostro dataset utilizzando solo le prime 4 componenti principali oppure mantenendo le prime 6.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbowA3FtBA8v"
      },
      "source": [
        "<a name=\"bilanciamento\"></a>\n",
        "##Bilanciamento Dataset \n",
        "\n",
        "Esistono diverse tecniche per bilanciare il dataset:\n",
        "- **oversampling:** tecnica che consente di creare dei campioni appartenenti alla classe con meno record;\n",
        "- **undersampling:** tecnica che consente di rimuovere dei campioni appartenenti alla classe con più record;\n",
        "- **class weight:** tecnica che consente di bilanciare il dataset inserendo un parametro chiamato \"weight\" all'interno del dataset, che contiene i pesi delle varie classi del dataset. Il peso viene assegnato in base alla proporzione tra il numero di parametri della classe più grande e il numero di parametri della classe più piccola. (per esempio W = 1 per la classe \"0\" e W = 10 per la classe \"1\") \n",
        "Durante la fase di train i vari record influenzeranno il modello in proporzione al peso assegnatogli.\n",
        "Questa è la soluzione meno invasiva, perché non modifica il dataset ma solamente il modo in cui i record agiscono sul modello.\n",
        "-**pipeline**: questa tecnica consiste nell'applicare sia l'oversampling sul dataset più piccolo, che l'undersampling sul dataset più grande.\n",
        "\n",
        "Per bilanciare questo dataset ho optato per la tecnica della pipeline, nella quale procederò a modificare i record di entrambe le classi.\n",
        "\n",
        "Il bilanciamento si deve eseguire solo sul train set, perché il test set deve essere più vicino possibile ai dati reali.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-uMg0xR6fBX",
        "outputId": "29fbce07-b0ee-4730-f2c1-e42f642fdd05"
      },
      "source": [
        "x = x_train_PCA4\n",
        "y = y_train\n",
        "\n",
        "model = SVC(kernel='linear', probability=True, random_state=42)\n",
        "scores = cross_val_score(model, x, y, scoring='roc_auc', cv=5, n_jobs=-1)\n",
        "score = mean(scores)\n",
        "print('Lo score calcolato sul dataset a cui è stata applicata la PCA mantenendo 4 componenti è:%.3f' % (score))\n",
        "\n",
        "x = x_train_PCA6\n",
        "model = SVC(kernel='linear', probability=True, random_state=42)\n",
        "scores = cross_val_score(model, x, y, scoring='roc_auc', cv=5, n_jobs=-1)\n",
        "score = mean(scores)\n",
        "print('Lo score calcolato sul dataset a cui è stata applicata la PCA mantenendo 6 componenti è:%.3f' % (score))\n",
        "\n",
        "x = X_train_norm\n",
        "model = SVC(kernel='linear', probability=True, random_state=42)\n",
        "scores = cross_val_score(model, x, y, scoring='roc_auc', cv=5, n_jobs=-1)\n",
        "score = mean(scores)\n",
        "print('Lo score calcolato sul dataset normalizzato è:%.3f' % (score))\n",
        "\n",
        "x = x_train_PCA6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lo score calcolato sul dataset a cui è stata applicata la PCA mantenendo 4 componenti è:0.935\n",
            "Lo score calcolato sul dataset a cui è stata applicata la PCA mantenendo 6 componenti è:0.975\n",
            "Lo score calcolato sul dataset normalizzato è:0.976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVz1RvYe7i1-"
      },
      "source": [
        "Applicando la PCA e tenendo le 6 features riusciamo a ridurre la dimensionalità del dataset senza perdere troppa risoluzione. Questo è dato dall'eliminazione di due features che nel complesso hanno una varianza dello 0,45%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEl3FLas68f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdc746fd-f354-4d51-e101-fb50d7bb8b27"
      },
      "source": [
        "#Bilanciamento dataset. da fare solo sul training set\n",
        "over_ratio = [0.3,0.4,0.5]\n",
        "under_ratio = [0.7,0.6,0.5]\n",
        "hi_score = 0\n",
        "best_ratio = (0,0)\n",
        "for o in over_ratio:\n",
        "  for u in under_ratio:\n",
        "    model = SVC(kernel='linear', probability=True, random_state=42)\n",
        "    over = SMOTE(sampling_strategy=o)\n",
        "    under = RandomUnderSampler(sampling_strategy=u)\n",
        "    steps = [('over', over), ('under', under), ('model', model)]\n",
        "    pipeline = Pipeline(steps=steps)\n",
        "    # evaluate pipeline\n",
        "    scores = cross_val_score(pipeline, x, y, scoring='roc_auc', cv=5, n_jobs=-1)\n",
        "    score = mean(scores)\n",
        "    if score > hi_score:\n",
        "      hi_score = score\n",
        "      best_ratio = (o,u)\n",
        "      print(\"cambio ratio {0} {1} \".format(o,u))\n",
        "    print('SMOTE oversampling rate:%.1f, Random undersampling rate:%.1f , Media ROC AUC: %.3f' % (o, u, score))\n",
        "print(\"Il ratio che restituisce un punteggio maggiore è (oversampling: {0},undersampling: {1})\".format(best_ratio[0],best_ratio[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cambio ratio 0.3 0.7 \n",
            "SMOTE oversampling rate:0.3, Random undersampling rate:0.7 , Media ROC AUC: 0.975\n",
            "SMOTE oversampling rate:0.3, Random undersampling rate:0.6 , Media ROC AUC: 0.975\n",
            "cambio ratio 0.3 0.5 \n",
            "SMOTE oversampling rate:0.3, Random undersampling rate:0.5 , Media ROC AUC: 0.976\n",
            "SMOTE oversampling rate:0.4, Random undersampling rate:0.7 , Media ROC AUC: 0.976\n",
            "cambio ratio 0.4 0.6 \n",
            "SMOTE oversampling rate:0.4, Random undersampling rate:0.6 , Media ROC AUC: 0.976\n",
            "SMOTE oversampling rate:0.4, Random undersampling rate:0.5 , Media ROC AUC: 0.975\n",
            "SMOTE oversampling rate:0.5, Random undersampling rate:0.7 , Media ROC AUC: 0.975\n",
            "SMOTE oversampling rate:0.5, Random undersampling rate:0.6 , Media ROC AUC: 0.976\n",
            "SMOTE oversampling rate:0.5, Random undersampling rate:0.5 , Media ROC AUC: 0.975\n",
            "Il ratio che restituisce un punteggio maggiore è (oversampling: 0.4,undersampling: 0.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_bhwb39L4MI"
      },
      "source": [
        "- **SMOTE** (Synthetic Minority Oversampling Technique), è una tecnica che seleziona due campioni appartenenti ad una classe che sono vicini tra loro, \"traccia una linea\" tra loro nello spazio delle features e crea un nuovo campione lungo questa linea.\n",
        "\n",
        "- **Random Undersampling:** Random undersampling è una tecnica che consente semplicemente nel rimuovere dei campioni casuali della classe più popolosa.\n",
        "\n",
        "- **Pipeline:** Tramite la pipeline è possibile effettuare in parallelo l'aumento di campione di una classe tramite SMOTE e la riduzione dell'altra classe tramite random undersampling.\n",
        "\n",
        "- **ROC AUC Score:** Una ROC è una curva che mostra le performance del classificatore, tenendo conto del *True Positive Rate* e del *False Positive Rate*. AUC, \"Area under the ROC Curve.\", misura l'area sotto la ROC curve. Questo punteggio è quindi calcolato applicando la tecnica di AUC sulla ROC.   \n",
        "\n",
        "- **SVC:** SVC (Support Vector Clustering) è un modello di apprendimento utilizzato per la classificazione, che estende il più famoso SVM (Support Vector Machine).\n",
        "\n",
        "Il punteggo relativo ai differenti ratio è molto simile tra loro, compreso il punteggio calcolato con il ratio originale. La scelta di uno rispetto all'altro non è troppo rilevante, quindi ho deciso di prendere (0.4,0.6) perchè mediamente ha performato leggermente meglio degli altri.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S2kOCfG3x2j"
      },
      "source": [
        "<a name=\"classificazione\"></a>\n",
        "##Classificazione"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3GkWRnjrDtV"
      },
      "source": [
        "In questa ultima parte proveremo vari modelli di classificazione sul nostro dataset per vedere quale si comporta meglio sui nostri dati."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NhI_41g45qR"
      },
      "source": [
        "kf = StratifiedKFold(n_splits=5, random_state=42, shuffle = True)\n",
        "\n",
        "lr = LogisticRegression(random_state=42)\n",
        "svm = SVC(probability=True, random_state=42)\n",
        "nbc = GaussianNB()\n",
        "rfc = RandomForestClassifier(random_state=42)\n",
        "knn = KNeighborsClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7RbubBTgsCg"
      },
      "source": [
        "<a name=\"lr\"></a>\n",
        "###Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_Sl6mLvgaqD"
      },
      "source": [
        "score = grid_search_cv(lr, LR_PARAM, x_train_PCA6, y_train, kf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcsLAk7uhIE5"
      },
      "source": [
        "<a name=\"svm\"></a>\n",
        "###Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfOnIFNuhK8B"
      },
      "source": [
        "score = grid_search_cv(svm, SVM_PARAM, x_train_PCA6, y_train, kf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ1NhrxthSxZ"
      },
      "source": [
        "<a name=\"nbc\"></a>\n",
        "###Naïve Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "nl2H-tKChdAr",
        "outputId": "e6b05d80-dd7c-4caf-f7de-6e58b82d4ece"
      },
      "source": [
        "score = grid_search_cv(nbc, NBC_PARAM, x_train_PCA6, y_train, kf)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a70608407336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_search_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVM_PARAM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_PCA6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'grid_search_cv' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5XtzNuDhhUe"
      },
      "source": [
        "<a name=\"rfc\"></a>\n",
        "###Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ER2HkN0hlMg"
      },
      "source": [
        "score = grid_search_cv(rfc, RFC_PARAM, x_train_PCA6, y_train, kf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sUi9OZjhp-E"
      },
      "source": [
        "<a name=\"knn\"></a>\n",
        "###K-Nearest Neighbors Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOc4kIs7huxL"
      },
      "source": [
        "score = grid_search_cv(knn, KNN_PARAM, x_train_PCA6, y_train, kf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fC3VJjQjePZ"
      },
      "source": [
        "<a name=\"conclusioni\"></a>\n",
        "##Conclusioni"
      ]
    }
  ]
}